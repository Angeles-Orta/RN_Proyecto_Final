# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fIJgCepZBFIB3PnncsCECj5iYTM-lGvx

Script de Inferencia para el Modelo de Análisis de Sentimientos LSTM
Redes Neuronales - Facultad de Ciencias, UNAM

Este script carga los pesos del modelo pre-entrenado y realiza inferencia
en nuevas reseñas sin necesidad de entrenar desde cero.

Archivos requeridos:
  - sentiment_model_weights.pth: Pesos del modelo
  - word_index.pkl: Diccionario palabra->índice

Uso:
    python inference.py

---
"""

import torch
import torch.nn as nn
import pickle
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences

class SentimentLSTM(nn.Module):
    """
    Modelo LSTM para clasificación de sentimientos.
    IMPORTANTE: Esta definición debe ser idéntica a la usada en entrenamiento.
    """

    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate):
        super(SentimentLSTM, self).__init__()

        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)

        self.lstm1 = nn.LSTM(
            input_size=embedding_dim,
            hidden_size=hidden_dim,
            num_layers=1,
            batch_first=True,
            dropout=0
        )

        self.dropout1 = nn.Dropout(dropout_rate)

        self.lstm2 = nn.LSTM(
            input_size=hidden_dim,
            hidden_size=hidden_dim // 2,
            num_layers=1,
            batch_first=True,
            dropout=0
        )

        self.dropout2 = nn.Dropout(dropout_rate)

        self.fc = nn.Linear(hidden_dim // 2, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        embedded = self.embedding(x)
        lstm_out1, _ = self.lstm1(embedded)
        lstm_out1 = self.dropout1(lstm_out1)
        lstm_out2, (hidden, cell) = self.lstm2(lstm_out1)
        lstm_out2 = self.dropout2(lstm_out2)
        last_hidden = hidden[-1]
        out = self.fc(last_hidden)
        out = self.sigmoid(out)
        return out.squeeze()

"""FUNCIÓN PARA CARGAR EL MODELO PRE-ENTRENADO"""

def load_trained_model(weights_path='sentiment_model_weights.pth',
                       word_index_path='word_index.pkl',
                       device='cpu'):
    """
    Carga el modelo pre-entrenado desde los archivos de pesos.

    Args:
        weights_path: Ruta al archivo con los pesos del modelo
        word_index_path: Ruta al diccionario de palabras
        device: 'cuda' o 'cpu'

    Returns:
        model: Modelo cargado en modo evaluación
        word_index: Diccionario palabra->índice
        config: Configuración del modelo
    """
    print("=== CARGANDO MODELO PRE-ENTRENADO ===\n")

    # Verificar dispositivo
    device = torch.device(device if torch.cuda.is_available() else 'cpu')
    print(f"Usando dispositivo: {device}")

    # Cargar pesos y configuración
    print(f"Cargando pesos desde: {weights_path}")
    checkpoint = torch.load(weights_path, map_location=device)

    model_state_dict = checkpoint['model_state_dict']
    config = checkpoint['config']

    print(f"\nConfiguración del modelo:")
    for key, value in config.items():
        print(f"  {key}: {value}")

    # Crear modelo con la configuración guardada
    model = SentimentLSTM(
        vocab_size=config['vocab_size'],
        embedding_dim=config['embedding_dim'],
        hidden_dim=config['hidden_dim'],
        dropout_rate=config['dropout_rate']
    ).to(device)

    # Cargar pesos
    model.load_state_dict(model_state_dict)
    model.eval()  # Modo evaluación (desactiva dropout)

    # Contar parámetros
    total_params = sum(p.numel() for p in model.parameters())
    print(f"\nParámetros totales: {total_params:,}")

    # Cargar diccionario de palabras
    print(f"\nCargando diccionario desde: {word_index_path}")
    with open(word_index_path, 'rb') as f:
        word_index = pickle.load(f)

    print(f"Vocabulario cargado: {len(word_index):,} palabras")
    print("\n✓ Modelo cargado exitosamente\n")

    return model, word_index, config

"""FUNCIÓN DE PREDICCIÓN"""

def predict_sentiment(model, text, word_index, max_length, device='cpu'):
    """
    Predice el sentimiento de una reseña de texto.

    Args:
        model: Modelo pre-entrenado
        text: Texto de la reseña (string)
        word_index: Diccionario palabra->índice
        max_length: Longitud máxima de secuencia
        device: Device de PyTorch

    Returns:
        sentiment: 'Positivo' o 'Negativo'
        probability: Probabilidad de sentimiento positivo [0-1]
        confidence: Nivel de confianza ('Alta', 'Media', 'Baja')
    """
    model.eval()
    device = torch.device(device)

    # Preprocesamiento del texto
    words = text.lower().split()

    # Convertir palabras a índices (usar 2 para palabras desconocidas)
    sequence = [word_index.get(word, 2) for word in words]

    # Aplicar padding
    sequence = pad_sequences([sequence], maxlen=max_length,
                            padding='post', truncating='post')

    # Convertir a tensor
    sequence_tensor = torch.LongTensor(sequence).to(device)

    # Predicción
    with torch.no_grad():
        probability = model(sequence_tensor).item()

    # Clasificar sentimiento
    sentiment = "Positivo" if probability > 0.5 else "Negativo"

    # Determinar confianza
    confidence_score = abs(probability - 0.5) * 2  # Normalizar a [0, 1]
    if confidence_score > 0.7:
        confidence = "Alta"
    elif confidence_score > 0.4:
        confidence = "Media"
    else:
        confidence = "Baja"

    return sentiment, probability, confidence

"""FUNCIÓN PARA BATCH DE PREDICCIONES"""

def predict_batch(model, texts, word_index, max_length, device='cpu'):
    """
    Realiza predicciones para múltiples reseñas.

    Args:
        model: Modelo pre-entrenado
        texts: Lista de strings con reseñas
        word_index: Diccionario palabra->índice
        max_length: Longitud máxima de secuencia
        device: Device de PyTorch

    Returns:
        results: Lista de tuplas (sentiment, probability, confidence)
    """
    model.eval()
    device = torch.device(device)

    results = []

    for text in texts:
        sentiment, probability, confidence = predict_sentiment(
            model, text, word_index, max_length, device
        )
        results.append((sentiment, probability, confidence))

    return results

"""EJEMPLOS DE USO"""

def demo_predictions(model, word_index, config):
    """
    Función de demostración con ejemplos de reseñas.
    """
    print("="*70)
    print("DEMOSTRACIÓN DE INFERENCIA")
    print("="*70)

    # Reseñas de ejemplo
    test_reviews = [
        "This movie was absolutely fantastic! Great acting and amazing plot.",
        "Terrible waste of time. Boring and predictable storyline.",
        "Not the best movie I've seen, but entertaining enough.",
        "Masterpiece! One of the greatest films ever made.",
        "Awful experience. Would not recommend to anyone.",
        "Pretty decent film with some good moments and some boring parts."
    ]

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    max_length = config['max_length']

    print("\nAnalizando reseñas...\n")

    for i, review in enumerate(test_reviews, 1):
        sentiment, probability, confidence = predict_sentiment(
            model, review, word_index, max_length, device
        )

        print(f"Reseña {i}:")
        print(f"  Texto: {review[:60]}{'...' if len(review) > 60 else ''}")
        print(f"  Sentimiento: {sentiment}")
        print(f"  Probabilidad: {probability:.4f} ({probability*100:.2f}%)")
        print(f"  Confianza: {confidence}")
        print()

"""MODO INTERACTIVO"""

def interactive_mode(model, word_index, config):
    """
    Modo interactivo para probar el modelo con reseñas propias.
    """
    print("="*70)
    print("MODO INTERACTIVO")
    print("="*70)
    print("\nEscribe reseñas de películas para analizar su sentimiento.")
    print("Escribe 'salir' para terminar.\n")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    max_length = config['max_length']

    while True:
        review = input("Reseña: ").strip()

        if review.lower() in ['salir', 'exit', 'quit']:
            print("\n¡Hasta luego!")
            break

        if not review:
            print("Por favor escribe una reseña.\n")
            continue

        sentiment, probability, confidence = predict_sentiment(
            model, review, word_index, max_length, device
        )

        print(f"\n  → Sentimiento: {sentiment}")
        print(f"  → Probabilidad: {probability:.4f} ({probability*100:.2f}%)")
        print(f"  → Confianza: {confidence}\n")

"""PROGRAMA PRINCIPA"""

def main():
    """
    Función principal del script de inferencia.
    """
    print("\n" + "="*70)
    print("ANÁLISIS DE SENTIMIENTOS - INFERENCIA CON MODELO PRE-ENTRENADO")
    print("Redes Neuronales - Facultad de Ciencias, UNAM")
    print("="*70 + "\n")

    # Cargar modelo
    try:
        model, word_index, config = load_trained_model(
            weights_path='sentiment_model_weights.pth',
            word_index_path='word_index.pkl',
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )
    except FileNotFoundError as e:
        print(f"\nError: No se encontraron los archivos necesarios.")
        print(f"   Asegúrate de tener:")
        print(f"   - sentiment_model_weights.pth")
        print(f"   - word_index.pkl")
        print(f"\n   Detalle del error: {e}")
        return

    # Ejecutar demos
    demo_predictions(model, word_index, config)

    # Modo interactivo
    response = input("¿Deseas probar el modelo con tus propias reseñas? (s/n): ")
    if response.lower() in ['s', 'si', 'y', 'yes']:
        interactive_mode(model, word_index, config)

    print("\n" + "="*70)
    print("INFERENCIA COMPLETADA")
    print("="*70)


if __name__ == "__main__":
    main()